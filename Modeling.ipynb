{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import mm_predictor # stat-analysis library\n",
    "from sklearn import cross_validation, linear_model\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from tpot.builtins import StackingEstimator\n",
    "from xgboost import XGBClassifier\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# intialize stat & elo dictionaries\n",
    "mm_predictor.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "season_data = pd.read_csv('./ncaa-data/RegularSeasonDetailedResults.csv')\n",
    "tourney_data = pd.read_csv('./ncaa-data/NCAATourneyDetailedResults.csv')\n",
    "tourney_data = tourney_data[tourney_data.Season != 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = pd.concat([season_data, tourney_data])\n",
    "\n",
    "X,Y = mm_predictor.analyze_teams(aggregated_data)\n",
    "# Run script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('stackingestimator-1', StackingEstimator(estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.01, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=4, missing=None, n_estimators=100, nthread=1,\n",
       "       objective='binary:logistic...ty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from tpot.builtins import StackingEstimator\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# NOTE: Make sure that the class is labeled 'target' in the data file\n",
    "# tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
    "# features = tpot_data.drop('target', axis=1).values\n",
    "# training_features, testing_features, training_target, testing_target = \\\n",
    "#             train_test_split(features, tpot_data['target'].values, random_state=42)\n",
    "\n",
    "# Score on the training set was:-0.5443811951009836\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=XGBClassifier(learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, nthread=1, subsample=0.15000000000000002)),\n",
    "    RobustScaler(),\n",
    "    StackingEstimator(estimator=GaussianNB()),\n",
    "    StackingEstimator(estimator=LinearSVC(C=15.0, dual=True, loss=\"hinge\", penalty=\"l2\", tol=0.0001)),\n",
    "    StackingEstimator(estimator=GaussianNB()),\n",
    "    LogisticRegression(C=5.0, dual=False, penalty=\"l1\")\n",
    ")\n",
    "\n",
    "# exported_pipeline = RandomForestClassifier(bootstrap=True, criterion=\"gini\", max_features=0.55, min_samples_leaf=5, min_samples_split=9, n_estimators=100)\n",
    "\n",
    "# exported_pipeline = DecisionTreeClassifier(criterion=\"gini\", max_depth=7, min_samples_leaf=11, min_samples_split=12)\n",
    "\n",
    "# exported_pipeline.fit(training_features, training_target)\n",
    "\n",
    "#exported_pipeline = LogisticRegression()\n",
    "\n",
    "exported_pipeline.fit(np.array(X), np.array(Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create id to team name mappings\n",
    "teamNames = pd.read_csv('./ncaa-data/Teams.csv')\n",
    "def teamIDNameMapping():\n",
    "    team_id_map = {}\n",
    "    for index, row in teamNames.iterrows():\n",
    "        team_id_map[row['TeamID']] = row['TeamName']\n",
    "    \n",
    "    return team_id_map\n",
    "\n",
    "team_id_map = teamIDNameMapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def WinChanceMapping(year):\n",
    "    \n",
    "    submission_data = []\n",
    "    tourney_seeds = pd.read_csv('./ncaa-data/TourneySeeds.csv')\n",
    "    tourney_teams = tourney_seeds[tourney_seeds['Season'] == year]['Team']\n",
    "\n",
    "    stat_fields = ['score', 'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF',\n",
    "                   'fgp', '3pp', 'ftp']\n",
    "    \n",
    "    tourney_teams.sort_values()\n",
    "    \n",
    "    for team_1 in tourney_teams:\n",
    "        for team_2 in tourney_teams:\n",
    "            if team_1 != team_2:\n",
    "                prediction = mm_predictor.predict_winner(\n",
    "                    team_1, team_2, exported_pipeline, 2017, stat_fields)\n",
    "                label = '2017_' + str(team_1) + '_' + str(team_2)\n",
    "                submission_data.append([label, prediction[0][0]])\n",
    "    \n",
    "    \n",
    "    teamTeamWinChanceMap = {}\n",
    "    for line in submission_data:\n",
    "        title = line[0].split('_')\n",
    "        team1 = team_id_map[int(title[1])]\n",
    "        team2 = team_id_map[int(title[2])]\n",
    "        winRate = str(round(line[1]* 100,2))\n",
    "        if team1 not in teamTeamWinChanceMap:\n",
    "            teamTeamWinChanceMap[team1] = {}\n",
    "        if float(winRate) >= 50:\n",
    "            if team1 in teamTeamWinChanceMap and team2 in teamTeamWinChanceMap[team1] and teamTeamWinChanceMap[team1][team2] > float(winRate):\n",
    "                continue\n",
    "            if team2 in teamTeamWinChanceMap and team1 in teamTeamWinChanceMap[team2] and teamTeamWinChanceMap[team2][team1] < float(winRate):\n",
    "                # update teamTeammap[team2][team1] to remove that key\n",
    "                teamTeamWinChanceMap[team2].pop(team1, None)\n",
    "            teamTeamWinChanceMap[team1][team2] = float(winRate)\n",
    "            \n",
    "    return teamTeamWinChanceMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"Writing %d results.\" % len(submission_data))\n",
    "# with open('./ncaa-data/submission.csv', 'w') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow(['id', 'pred'])\n",
    "#     writer.writerows(submission_data)\n",
    "\n",
    "chanceMap = WinChanceMapping(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterTourneyDataByYear(year):\n",
    "\n",
    "    tourney_data = pd.read_csv('./ncaa-data/NCAATourneyDetailedResults.csv')\n",
    "    tourney_data = tourney_data[tourney_data.Season == year]\n",
    "    \n",
    "    return tourney_data\n",
    "\n",
    "def getWinnersList(tourney_data):\n",
    "    winners = []\n",
    "\n",
    "    tourney_data_grouped = tourney_data[4:].groupby('WTeamID').size().reset_index(name='NumWins')\n",
    "    for index, row in tourney_data_grouped.iterrows():\n",
    "        teamName = team_id_map[row['WTeamID']]\n",
    "        wins = row['NumWins']\n",
    "        if len(winners) == 0:\n",
    "            winners.append([])\n",
    "        winners[0].append(teamName)\n",
    "        if wins > 1:\n",
    "            if len(winners) == 1:\n",
    "                winners.append([])\n",
    "            winners[1].append(teamName)\n",
    "        if wins > 2:\n",
    "            if len(winners) == 2:\n",
    "                winners.append([])\n",
    "            winners[2].append(teamName)\n",
    "        if wins > 3:\n",
    "            if len(winners) == 3:\n",
    "                winners.append([])\n",
    "            winners[3].append(teamName)\n",
    "        if wins > 4:\n",
    "            if len(winners) == 4:\n",
    "                winners.append([])\n",
    "            winners[4].append(teamName)\n",
    "        if wins > 5:\n",
    "            if len(winners) == 5:\n",
    "                winners.append([])\n",
    "            winners[5].append(teamName)\n",
    "        if wins > 6:\n",
    "            if len(winners) == 6:\n",
    "                winners.append([])\n",
    "            winners[6].append(teamName)\n",
    "    \n",
    "    return winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method that takes in season's tournament data, id to name mapping of teams\n",
    "def calcBracketScore(teamTeamWinChanceMap, tourney_data):\n",
    "    \n",
    "    winners = getWinnersList(tourney_data)\n",
    "    \n",
    "    # First four rows is 'first four' and not in actual bracket\n",
    "    firstFour = tourney_data[:4]\n",
    "    mainTourney = tourney_data[4:]\n",
    "    \n",
    "    tourney_seeds = pd.read_csv('./ncaa-data/TourneySeeds.csv')\n",
    "    \n",
    "    tourney = [-1] * max(tourney_seeds['Team'])\n",
    "\n",
    "    # Look at first four teams\n",
    "    for index, row in firstFour.iterrows():\n",
    "        index1 = int(row['WTeamID'])\n",
    "        index2 = int(row['LTeamID'])\n",
    "        team1Name = team_id_map[index1]\n",
    "        team2Name = team_id_map[index2]\n",
    "\n",
    "        if (team1Name in teamTeamWinChanceMap) and (team2Name in teamTeamWinChanceMap[team1Name]):\n",
    "            tourney[index2] = index1\n",
    "        else:\n",
    "            tourney[index1] = index2\n",
    "\n",
    "    # MAIN TOURNAMENT \n",
    "    score = 0\n",
    "    for index, row in mainTourney.iterrows():\n",
    "        index1 = int(row['WTeamID'])\n",
    "        index2 = int(row['LTeamID'])\n",
    "        while tourney[index1] > 0:\n",
    "            index1 = tourney[index1]\n",
    "        while tourney[index2] > 0:\n",
    "            index2 = tourney[index2]\n",
    "        team1Name = team_id_map[index1]\n",
    "        team2Name = team_id_map[index2]\n",
    "\n",
    "        if (team1Name in teamTeamWinChanceMap) and (team2Name in teamTeamWinChanceMap[team1Name]): # team1 would win\n",
    "            tourney[index2] = index1\n",
    "            tourney[index1] = tourney[index1] - 1\n",
    "            if team1Name in winners[abs(tourney[index1]) - 2]:\n",
    "                score += 2**(abs(tourney[index1]) - 2) * 10\n",
    "#                 print(team1Name + ' vs ' + team2Name + ', team 1 wins')\n",
    "#                 print('Score ' + str(2**(abs(tourney[index1]) - 2) * 10))\n",
    "#             else: # Delete else statemenet when done debugging\n",
    "#                 print('Incorrect: Predicted ' + team1Name + ' vs ' + team2Name + ', team1 wins')\n",
    "\n",
    "        else: #team2 would win\n",
    "            tourney[index1] = index2\n",
    "            tourney[index2] = tourney[index2] - 1\n",
    "            if team2Name in winners[abs(tourney[index2]) - 2]:\n",
    "                score += 2**(abs(tourney[index2]) - 2) * 10\n",
    "#                 print(team1Name + ' vs ' + team2Name + ', team 2 wins')\n",
    "#                 print('Score ' + str(2**(abs(tourney[index1]) - 2) * 10))\n",
    "#             else: # Delete else statement when done debugging\n",
    "#                 print('Incorrect: Predicted ' + team1Name + ' vs ' + team2Name + ', team2 wins')\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "data_2017 = filterTourneyDataByYear(2017)\n",
    "data_2017\n",
    "print(calcBracketScore(chanceMap, data_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11']\nexpected f15, f13, f19, f24, f12, f17, f20, f27, f18, f26, f14, f16, f23, f21, f25, f22 in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1120e209b77c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mexported_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mchanceMap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWinChanceMapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2017\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalcBracketScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchanceMap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2017\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-caabe73378ce>\u001b[0m in \u001b[0;36mWinChanceMapping\u001b[0;34m(year)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mteam_1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mteam_2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 prediction = mm_predictor.predict_winner(\n\u001b[0;32m---> 16\u001b[0;31m                     team_1, team_2, exported_pipeline, 2017, stat_fields)\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2017_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteam_1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteam_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0msubmission_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Winter 2018/Info 370 Data Science/info370-FinalProject/mm_predictor.py\u001b[0m in \u001b[0;36mpredict_winner\u001b[0;34m(team_1, team_2, model, season, sf)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;31m# features.append(get_elo(season, team_2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_stat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/site-packages/tpot/builtins/stacking_estimator.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# add class probabilities as a synthetic feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassifierMixin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict_proba'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mX_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# add class prodiction as a synthetic feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[1;32m    475\u001b[0m         class_probs = self.booster().predict(test_dmatrix,\n\u001b[1;32m    476\u001b[0m                                              \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m                                              ntree_limit=ntree_limit)\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multi:softprob\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mclass_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf)\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0moption_mask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;36m0x02\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1179\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11']\nexpected f15, f13, f19, f24, f12, f17, f20, f27, f18, f26, f14, f16, f23, f21, f25, f22 in input data"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "data_2017 = filterTourneyDataByYear(2017)\n",
    "\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    X,Y = mm_predictor.analyze_teams(aggregated_data)\n",
    "    \n",
    "    exported_pipeline = make_pipeline(\n",
    "        StackingEstimator(estimator=XGBClassifier(learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=100, nthread=1, subsample=0.15000000000000002)),\n",
    "        RobustScaler(),\n",
    "        StackingEstimator(estimator=GaussianNB()),\n",
    "        StackingEstimator(estimator=LinearSVC(C=15.0, dual=True, loss=\"hinge\", penalty=\"l2\", tol=0.0001)),\n",
    "        StackingEstimator(estimator=GaussianNB()),\n",
    "        LogisticRegression(C=5.0, dual=False, penalty=\"l1\")\n",
    "    )\n",
    "    \n",
    "    exported_pipeline.fit(np.array(X), np.array(Y))\n",
    "    \n",
    "    chanceMap = WinChanceMapping(2017)\n",
    "    \n",
    "    score.append(calcBracketScore(chanceMap, data_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def bracketScorer(y_true, y_predicted):\n",
    "#     # y_predicted must be a chance map... we don't care what y_true is rofl\n",
    "#     bracket = filterTourneyDataByYear(2017)\n",
    "#     chanceMap = WinChanceMapping(2017)\n",
    "#     return calcBracketScore(chanceMap, bracket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import make_scorer\n",
    "\n",
    "# bballScorer = make_scorer(bracketScorer, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tppot = TPOTClassifier(generations = 1, max_time_mins=780, verbosity=2, scoring = bballScorer, population_size=10)\n",
    "\n",
    "# tppot.fit(np.array(X), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
